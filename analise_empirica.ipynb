{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de Análise de Algoritmos - Análise empírica\n",
    "\n",
    "Propõe-se neste trabalho realizar uma análise algoritmica empírica de um programa considerado \"útil\". Desta forma, escolheu-se o algoritmo de classificação K-Nearest Neighbors (K-NN).\n",
    "\n",
    "O K-NN é um algoritmo de aprendizagem de máquina que utiliza uma projeção N-dimensional dos dados. Por meio desta projeção e uma quantidade de dados conhecida (rotulados de forma que se sabe a quais classes pertence cada dado), ele classifica um novo dado informando a sua classe correta por meio da verificação dos `K` vizinhos mais próximos a ele. É utilizado uma quantidade ímpar de vizinhos verificados a cada novo dado para não haver condição de empate. Ao julgar quais são as classes dos vizinhos mais próximos, o novo dado é classificado de acordo com a classe mais votada.\n",
    "\n",
    "Um exemplo de aplicação do algoritmo de classificação K-NN é mostrado no gráfico a seguir, no qual um novo exemplo (círculo vermelho de interrogação) é verificado se é um **Salmão** ou se é um **Robalo**.\n",
    "\n",
    "![alt text](grafico_knn.png \"Gráfico do Robalos e Salmões\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo K-NN a seguir é utilizado para a identificação de digitos em uma base de dados. Uma base de dados com imagens de vários dígitos de 0 à 9 é utilizado para \"treinar\" o algoritmo, ou seja, para criar o gráfico 9-dimensional para classificação. Este código implementa uma versão simples do algoritmo de classificação KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realização dos imports das bibliotecas\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def class_histogram(kn_neighbors, n_classes):\n",
    "    '''Faz a contagem das classes dos k vizinhos mais próximos.\n",
    "    Recebe o vetor com os k mais próximos.'''\n",
    "    \n",
    "    # Cria um vetor c zerado com n_classes posições\n",
    "    c = [0] * n_classes\n",
    "    # Para cada vizinho entre os k mais próximos\n",
    "    for i in kn_neighbors:\n",
    "        # incrementar contagem\n",
    "        c[i] += 1\n",
    "    # retorna contagem das classes dos k vizinhos mais próximos\n",
    "    return c\n",
    "\n",
    "def knn(X_train, Y_train, x, k):\n",
    "    '''Faz a classificação do exemplo x baseado nos k mais próximos em X_train.'''\n",
    "    \n",
    "    # Calcula o vetor de distâncias entre x e todos os pontos em X_train\n",
    "    d = euclidean_distances(x.reshape(1, -1), X_train).reshape(-1)\n",
    "    \n",
    "    # Ordena o vetor d e retorna os índices da ordenação em relação ao vetor d original. Não mexe no vetor d.\n",
    "    # Isto ajuda porque é necessário indexar Y_train das posições correspondentes depois da ordenação!\n",
    "    idx = np.argsort(d)\n",
    "    # Calcula a contagem das classes dos k vizinhos mais próximos:\n",
    "    # Y_train[idx][:k] <-- obtém os rótulos dos k vizinhos mais próximos!\n",
    "    hist = class_histogram(Y_train[idx][:k], len(set(Y_train)))\n",
    "    # hist apenas é um vetor [c0, c1, c2, ..., c_nclasses] de forma que c0 é a quantidade de vizinhos mais\n",
    "    # próximos que são da classe 0, c1 é a quantidade de vizinhos mais proximos que são da classe 1, e \n",
    "    # assim por diante.\n",
    "    \n",
    "    # O knn classifica x como sendo da classe com a maior quantidade de vizinhos mais próximos. Assim,\n",
    "    # basta retornar a posição da classe que tem a maior quantidade de vizinhos mais próximos.\n",
    "    #    ex: se np.argmax(hist) == 0, a classe 0 tem a maioria dos vizinhos mais próximos de x.\n",
    "    return np.argmax(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções declaradas anteriormente realizam a contagem dos vizinhos mais próximos (`class_histogram`) e realiza a classificação de um novo elemento baseado no parâmetro passado (`knn`).\n",
    "\n",
    "O trecho a seguir realiza o carregamento da base de ddos de digitos e separa 70% das amostras para \"treinamento\" do algoritmo e 30% para testar os vizinhos mais próximos (\"teste\" do algoritmo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 99.17%\n"
     ]
    }
   ],
   "source": [
    "# Carrega um dataset ``digits'' do sklearn. Esse dataset é composto de 1797 imagens de dígitos manuscritos \n",
    "# 8x8 em 16 tons de cinza. Há 64 características por imagem, uma para o valor de cada pixel.\n",
    "X, Y = load_digits(return_X_y=True)\n",
    "\n",
    "# Vamos dividir o dataset com 70% no treino e 30% no teste. X_train é o conjunto de treino com os exemplos\n",
    "# e Y_train são os gabaritos de cada exemplo de X_train. X_test é o conjunto de treino com os exemplos e \n",
    "# Y_test são os gabaritos de cada exemplo de X_test se shuffle=True, \"embaralha\" o dataset antes de fazer\n",
    "# a separação.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
    "\n",
    "misses, hits = 0, 0\n",
    "k = 3\n",
    "\n",
    "# Para cada exemplo no conjunto de teste\n",
    "for i, x in enumerate(X_test):\n",
    "    # Classificar o exemplo. Se o exemplo estiver correto (for igual do gabarito)\n",
    "    if knn(X_train, Y_train, x, k) == Y_test[i]:\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "\n",
    "# A acurácia é dada por acertos / (acertos + erros).\n",
    "print (\"Acurácia: %.02f%%\" % (hits / float(hits + misses) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise do algoritmo completo\n",
    "\n",
    "Com este conjunto algoritmo exposto, realize a análise algoritmica empírica do problema. Leve em consideração o custo de **ordenações** (QuickSort) e o **cálculo da distância euclidiana** dentro da função `knn`. Para o restante dos trechos de código deve se analizar o tamanho da entrada e os loops. Considere também que as funções `load_digits` e `train_test_split` são constantes.\n",
    "\n",
    "Vocês deverão **instrumentar os códigos acima** para contabilizar a **quantidade de instruções**. Além disso, realizar a **análise assintótica** formal do problema e, no final, comparar o custo assintótico e empírico do problema.\n",
    "\n",
    "## Entrega:\n",
    "\n",
    "O trabalho poderá ser realizado no máximo em duplas. A entrega será realizada até o dia 09 de julho no moodle. Deve ser entregue um pacote compactado por apenas um aluno do grupo contendo o relatório e os códigos desenvolvidos). Este trabalho valerá **1,5 pontos na média**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
